---
title: "Estimating Heterogeneous Exposure Effects using CL-BART"
author: "Anonymous"
date: "18 April 2024"
output: 
  rmarkdown::pdf_document:
    citation_package: natbib
bibliography: ../vignettes/materials/clbart-package-vignette.bib
vignette: >
  %\VignetteIndexEntry{Estimating Heterogeneous Exposure Effects using CL-BART}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE, message = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(tidyverse)
fit <- read_rds('../vignettes/materials/fit.rds')
marg_ale <- read_rds('../vignettes/materials/marg_ale.rds')
joint_ale <- read_rds('../vignettes/materials/joint_ale.rds')
```

## Setup
First, ensure you have loaded the `clbart` package into your R session. We will also make use of the `tidyverse` package for some data manipulation and plotting.
```{r setup, message = FALSE}
library(clbart)
library(tidyverse)
```

## Simulate Data
To mimic the case-crossover design, we will follow 10,000 individuals for 1 year. We will consider 10 time-invariant covariates `w`, and 5 time-varying covariates `x`.

```{r}
# Setup
set.seed(1)
n       <- 10000
start   <- as.Date("2023-01-01")
end     <- as.Date("2023-12-31")
dates   <- seq.Date(start, end, by = 'day')
t       <- length(dates)
p_w     <- 10
p_x     <- 5

# Simulate shared exposure time-series
z <- rnorm(t, sin(seq(0, 2 * pi, length.out = t)))

# Simulate independent time-varying confounders
x <- replicate(p_x, runif(t))
colnames(x) <- paste0('X', 1:p_x)

# Simulate independent time-invariant moderators
w <- replicate(p_w, runif(n))
colnames(w) <- paste0('W', 1:p_w)

# Construct data frame of time-varying variables
xz <- data.frame(x, Z = z, date = dates) |>
  mutate(year = year(date), month = month(date), dow = wday(date))

# Data frame of all individuals at all times
data <- cross_join(data.frame(strata = 1:n, w), xz)
```

We then simulate the outcome based on coefficients. For the exposure effect, we use a modification of the classic Friedman function \citep{friedman_greedy_2001}.

```{r}
# Heterogeneous exposure log odds-ratios
f0 <- function(x) 10 * sin(pi*x[,1]*x[,2]) + 20*(x[,3]-.5)^2 + 10*x[,4] + 5*x[,5]
f <- function(x) (f0(x) - 14) / 15
tau <- f(data[,colnames(w)])

# Fixed effects
alpha <- -8 # intercept
beta <- log(c(0.5, 0.8, 1.0, 1.2, 2.0)) # confounder log odds-ratios

# Calculate probabilities
expit <- function(x) exp(x) / (1 + exp(x))
p <- expit(alpha + as.matrix(data[,colnames(x)]) %*% beta + tau * data$Z)[,1]

# Store probabilities and log-odds in dataset
data$tau <- tau
data$p <- p

# Generate outcome
y <- rbinom(n * t, 1, data$p)
```

## Implement the Case-Crossover Design
We then filter down to the cases only (as this is what is typically observed), and implement the time-stratified case-crossover design. This involves matching each observed case to the other days in the calendar month which share the same day of the week.

```{r}
# Implement time-stratified case-crossover design
cco <- data[which(y == 1),] |>  # subset cases
  mutate(strata = row_number()) |>  # assign unique ID (strata) to each case
  select(-all_of(c(colnames(x), 'Z'))) |>
  left_join(xz, by = c('year', 'month', 'dow'), relationship = 'many-to-many') |>
  mutate(Y = ifelse(date.x == date.y, 1, 0)) |> # create case variable
  select(-date.x) |>
  rename(date = date.y)
```

## Fitting the Model

CL-BART seeks to estimate parameters from the following likelihood:
$$\pi(\mathbf{y} \mid \tau(\cdot), \mathbf{\beta}) = \prod_{i=1}^n \pi(\mathbf{y}_i \mid \tau(\cdot), \mathbf{\beta}) = \prod_{i=1}^n \frac{\exp \left\{\mathbf{x}_{it_i}^T\mathbf{\beta} + \tau(\mathbf{w}_i) z_{it_i} \right\}}{\sum_{t \in \mathcal{W}_i} \exp \left\{\mathbf{x}_{it}^T\mathbf{\beta} + \tau(\mathbf{w}_i) z_{it} \right\}}$$
where $\mathbf{y}$, $\mathbf{x}$, $\mathbf{w}$, and $z$ are the matrices/vectors we have generated thus far. The referent window $\mathcal{W}_i$ represents all observed times for individual $i$. We incorporate this using the `strata` vector, where `strata` represents the groupings of observations by individual.

```{r}
# Prepare CCO data for model
w <- cco[colnames(w)]
x <- cco[colnames(x)]
z <- cco$Z
y <- cco$Y
strata <- cco$strata
```

Cl-BART uses Bayesian additive regression trees \citep{chipman_bart_2010} to estimate the exposure moderating function $\tau(\cdot)$, which has several options for hyperparameter settings. Fitting a `clbart` model requires specifying the hyperparameters via `Hypers()` and the options via `Opts()`. For this example we run a 20 tree model for 2500 MCMC iterations, saving the final 500 iterations. We also set the `update_s` and `update_alpha` options to `TRUE`, which improves variable selection via the Dirichlet prior modification introduced in \citet{linero_bayesian_2018}.

```{r, eval = FALSE}
# Specify hyperparameters for fitting clbart model
hypers <- Hypers(num_tree = 20, k = 1)
opts <- Opts(update_s = TRUE, update_alpha = TRUE,
             num_burn = 2000, num_thin = 1, num_save = 500)

# Fit clbart model
fit <- clbart(w, x, y, z, strata, hypers, opts)
```

## Summarizing Model Results

Once the model is fit (make take a while), we can examine it.
```{r}
# Obtain a brief summary of the model fit
fit_sum <- summary(fit)

# Check beta (confounder) estimates
fit_sum$beta_stats
beta
```
The estimated $\beta$ coefficients are similar to what we specified above.

More interestingly, we can plot the predictions for $\tau(\mathbf{w})_i$, stored in `fit$lambda_est`. These are the posterior mean BART predictions. By default, only the posterior means are returned. However, setting `store_lambda = TRUE` inside of `Opts()` will keep the entire posterior distribution of all predictions.
```{r, fig.width=6, fig.height = 4, fig.align='center', fig.cap = 'CL-BART Predictions vs. Truth'}
# Plot individual BART predictions versus the true association
plot(fit$lambda_est ~ cco$tau,
     xlab = 'Truth', ylab = 'Prediction')
abline(a = 0, b = 1, col = 'red', lty = 2)
```

We can also view the proportion of splits based on each moderating covariate, the probability of splitting based on each covariate, and the posterior inclusion probability for each covariate.
```{r}
# Check variable importance measures
fit_sum$var_imp
```
Here we see that the first 5 covariates are split upon more often and included more often.

We can visualize the marginal effect of each moderator using accumulated local effects \citep{apley_visualizing_2020}. For Bayesian models, we can compute the ALE using the `bayes_ale()` function from the `pdpd` R package available \textcolor{blue}{here}.  
```{r, eval = FALSE}
library(pdpd)
f_hat <- function(w) predict(fit, list(w = w), type = "bart", posterior = TRUE)
firsts <- match(unique(strata), strata)

# Compute ALE
marg_ale <- lapply(colnames(w),
                   \(v) bayes_ale(w[firsts,], f_hat, vars = v, k = 40, f = f))
```

Now we plot the marginal ALE functions.

```{r, fig.cap='Accumulated Local Effects Plots for Effect Moderators'}
marg_ale |>
  bind_rows() |>
  ggplot(aes(x = x, y = est, ymin = lcl, ymax = ucl)) +
  geom_line() +
  geom_line(aes(y = truth), col = 'red', lty = 2) +
  geom_ribbon(alpha = 0.2) +
  facet_wrap(~factor(var, colnames(w)), nrow = 2) +
  theme_bw() +
  labs(x = 'Covariate Value', 
       y = 'Posterior Mean ALE w/ 95% Credible Interval')
```

Even with only 20 trees, the model does a fairly good job of approximates the true functional forms of the important effect moderators, and accurately estimates null effects for the unimportant covariates.

## Diagnostics
Posterior samples for most quantities are available in the model. This makes it easy to assess trace plots, such as for the average BART prediction.
```{r, fig.cap='Trace Plot of Average BART Prediction', fig.align='center'}
plot(fit$lambda_mean_overall, type = 'l',
     xlab = 'Posterior Sample Index', ylab = 'Average Prediction')
```

We can also extract the model WAIC. Which may be useful to compare multiple CL-BART models.
```{r}
fit$WAIC
```
